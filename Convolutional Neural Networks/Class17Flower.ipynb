{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17-Class Flower Image Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D,MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras.applications import vgg16, inception_v3, resnet50, mobilenet, vgg19\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.vgg19 import preprocess_input \n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified AlexNet\n",
    "def modifiedAlexnet(width, height, depth, classes):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Convolutional Layer\n",
    "    model.add(Conv2D(filters=96, input_shape=(width,height,depth), kernel_size=(11,11),\n",
    "                     strides=(4,4), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "    # Batch Normalisation before passing it to the next layer\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 2nd Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 4th Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 5th Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Passing it to a dense layer\n",
    "    model.add(Flatten())\n",
    "    # 1st Dense Layer\n",
    "    model.add(Dense(4096, input_shape=(width*height*depth,)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    model.add(Dropout(0.4))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 2nd Dense Layer\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation('relu'))\n",
    "    # Add Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 3rd Dense Layer\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Activation('relu'))\n",
    "    # Add Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add full path of dataset \n",
    "data_dir = 'flowers17'\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 128\n",
    "# Number of Epochs\n",
    "epochs = 75\n",
    "\n",
    "# Data preprocessing and Data Augmentation\n",
    "\n",
    "datagen_train = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_dir,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    target_size=(224,224),\n",
    "                                                    shuffle = True,\n",
    "                                                    class_mode = 'categorical')\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory(  directory=test_dir,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    target_size=(224,224),\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps per test and number of steps per epoch\n",
    "steps_test = generator_test.n // batch_size\n",
    "print(\"\\nNumber of steps per test :\",steps_test)\n",
    "\n",
    "steps_per_epoch = generator_train.n // batch_size\n",
    "print(\"\\nNumber of steps per epoch:\",steps_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL \n",
    "model = modifiedALextnet(224,224,3,17)\n",
    "\n",
    "# Model Summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Adam & rmrprop Optimizer \n",
    "#rms = keras.optimizers.RMSprop(lr=0.0001,epsilon=None, decay=0.0)\n",
    "Adam = keras.optimizers.adam(lr=0.001,beta_1=0.9,amsgrad = True)\n",
    "\n",
    "# Compile the Model \n",
    "# Using categorical crossentropy and accuracy for metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer= Adam, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model \n",
    "history= model.fit_generator(generator_train,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_data = generator_test,\n",
    "                           validation_steps = steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "plt.plot(history.history['loss'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=5.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=25)\n",
    "plt.ylabel('Loss',fontsize=25)\n",
    "plt.title('Loss Curves',fontsize=25)\n",
    "\n",
    "plt.figure(figsize=[20,20])\n",
    "plt.plot(history.history['acc'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=5.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=25)\n",
    "plt.ylabel('Accuracy',fontsize=25)\n",
    "plt.title('Accuracy Curves',fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation and preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 64\n",
    "# Number of Epochs\n",
    "epochs = 75\n",
    "\n",
    "# Data preprocessing and Data Augmentation\n",
    "\n",
    "datagen_train = ImageDataGenerator(shear_range =0.2 ,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   rescale=1./255)\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_dir,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    target_size=(224,224),\n",
    "                                                    shuffle = True,\n",
    "                                                    class_mode = 'categorical')\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory(  directory=test_dir,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    target_size=(224,224),\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Adam Optimizer \n",
    "Adam = keras.optimizers.adam(lr=0.001,beta_1=0.9,amsgrad = True)\n",
    "\n",
    "# Compile the Model \n",
    "# Using categorical crossentropy and accuracy for metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer= Adam, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model \n",
    "history= model.fit_generator(generator_train,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_data = generator_test,\n",
    "                           validation_steps = steps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "plt.plot(history.history['loss'],'k',linewidth=5.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=5.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=25)\n",
    "plt.ylabel('Loss',fontsize=25)\n",
    "plt.title('Loss Curves',fontsize=25)\n",
    "\n",
    "plt.figure(figsize=[20,20])\n",
    "plt.plot(history.history['acc'],'k',linewidth=5.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=5.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=25)\n",
    "plt.ylabel('Accuracy',fontsize=25)\n",
    "plt.title('Accuracy Curves',fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on pre-trained network : Transfer Learning : Fine Tuning top layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = inception_v3.InceptionV3(weights = 'imagenet', include_top = False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "predictions = Dense(17, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs = predictions)\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    \n",
    "    layer.trainable = False \n",
    "\n",
    "    \n",
    "              \n",
    "optimizer = keras.optimizers.Adam(lr=0.0001,beta_1=0.9,amsgrad=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit_generator(generator_train,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_data = generator_test,\n",
    "                           validation_steps = steps_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing training loss and validation loss\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['loss'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_loss'],'y',linewidth=5.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Loss',fontsize=20)\n",
    "plt.title('Loss Curves using Inception_V3',fontsize=20)\n",
    "\n",
    "\n",
    "# Plot showing training accuracy and validation accuracy \n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['acc'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_acc'],'y',linewidth=5.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.title('Accuracy Curves using Inception_V3',fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = resnet50.ResNet50(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "predictions = Dense(17, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs = predictions)\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    \n",
    "    layer.trainable = False \n",
    "\n",
    "   \n",
    "              \n",
    "optimizer = keras.optimizers.Adam(lr=0.0001,beta_1=0.9,amsgrad=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit_generator(generator_train,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_data = generator_test,\n",
    "                           validation_steps = steps_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing training loss and validation loss\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['loss'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_loss'],'y',linewidth=5.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Loss',fontsize=20)\n",
    "plt.title('Loss Curves using ResNet50',fontsize=20)\n",
    "\n",
    "\n",
    "# Plot showing training accuracy and validation accuracy \n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['acc'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_acc'],'y',linewidth=5.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.title('Accuracy Curves using ResNet50',fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = mobilenet.MobileNet(input_shape=(224,224,3),include_top= False, weights='imagenet')\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "predictions = Dense(17, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs = predictions)\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    \n",
    "    layer.trainable = False \n",
    "\n",
    "   \n",
    "              \n",
    "optimizer = keras.optimizers.Adam(lr=0.0001,beta_1=0.9,amsgrad=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit_generator(generator_train,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_data = generator_test,\n",
    "                           validation_steps = steps_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing training loss and validation loss\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['loss'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_loss'],'y',linewidth=5.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Loss',fontsize=20)\n",
    "plt.title('Loss Curves using mobileNet',fontsize=20)\n",
    "\n",
    "\n",
    "# Plot showing training accuracy and validation accuracy \n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['acc'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_acc'],'y',linewidth=5.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.title('Accuracy Curves using mobileNet',fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.xception.Xception(include_top=False, weights='imagenet',input_shape=None)\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "predictions = Dense(17, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs = predictions)\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    \n",
    "    layer.trainable = False \n",
    "\n",
    "   \n",
    "              \n",
    "optimizer = keras.optimizers.Adam(lr=0.0001,beta_1=0.9,amsgrad=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit_generator(generator_train,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_data = generator_test,\n",
    "                           validation_steps = steps_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing training loss and validation loss\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['loss'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_loss'],'y',linewidth=5.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Loss',fontsize=20)\n",
    "plt.title('Loss Curves using xception',fontsize=20)\n",
    "\n",
    "\n",
    "# Plot showing training accuracy and validation accuracy \n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['acc'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_acc'],'y',linewidth=5.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.title('Accuracy Curves using xception',fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = vgg19.VGG19(weights = 'imagenet', include_top = False)\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "predictions = Dense(17, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs = predictions)\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    \n",
    "    layer.trainable = False \n",
    "\n",
    "              \n",
    "optimizer = keras.optimizers.Adam(lr=0.0001,beta_1=0.9,amsgrad=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit_generator(generator_train,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_data = generator_test,\n",
    "                           validation_steps = steps_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing training loss and validation loss\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['loss'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_loss'],'y',linewidth=5.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Loss',fontsize=20)\n",
    "plt.title('Loss Curves using VGG19',fontsize=20)\n",
    "\n",
    "\n",
    "# Plot showing training accuracy and validation accuracy \n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['acc'],'r',linewidth=5.0)\n",
    "plt.plot(history.history['val_acc'],'y',linewidth=5.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.title('Accuracy Curves using VGG19',fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = vgg16.VGG16(weights = 'imagenet', include_top = False)\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "predictions = Dense(17, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs = predictions)\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    \n",
    "    layer.trainable = False \n",
    "              \n",
    "optimizer = keras.optimizers.Adam(lr=0.0001,beta_1=0.9,amsgrad=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit_generator(generator_train,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_data = generator_test,\n",
    "                           validation_steps = steps_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing training loss and validation loss\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['loss'],'b',linewidth=5.0)\n",
    "plt.plot(history.history['val_loss'],'k',linewidth=5.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Loss',fontsize=20)\n",
    "plt.title('Loss Curves using VGG_16',fontsize=20)\n",
    "\n",
    "\n",
    "# Plot showing training accuracy and validation accuracy \n",
    "plt.figure(figsize=[15,15])\n",
    "plt.plot(history.history['acc'],'b',linewidth=5.0)\n",
    "plt.plot(history.history['val_acc'],'k',linewidth=5.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=25)\n",
    "plt.xlabel('Epochs ',fontsize=20)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.title('Accuracy Curves using VGG_16',fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
