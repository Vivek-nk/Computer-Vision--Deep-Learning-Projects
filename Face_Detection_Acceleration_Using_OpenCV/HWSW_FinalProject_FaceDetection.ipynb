{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HWSW Project face detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import os\n",
    "import cv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import pylab as pl\n",
    "from fnmatch import fnmatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Original: call def detectFace(path, cascade):\n",
    "\n",
    "# new call : now passes in four new parameters : scaleFactor, minNeighbors, minSize, maxSize\n",
    "def detectFace(path, cascade, scaleFactor=1.3, minNeighbors=4, minSize=(20,20), maxSize=(200,200)):   \n",
    " \n",
    "    # Read image and convert to gray\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.cv.CV_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "     \n",
    "    # Base parameters \n",
    "    # Hint: re-write detectFace to pass in changes to parameters\n",
    "    # Original rects = cascade.detectMultiScale(img, 1.3, 4, cv2.cv.CV_HAAR_SCALE_IMAGE, (20,20),(200,200))\n",
    "    rects = cascade.detectMultiScale(img, scaleFactor, minNeighbors, cv2.cv.CV_HAAR_SCALE_IMAGE, minSize, maxSize)\n",
    "\n",
    "    if len(rects) == 0:\n",
    "        return [], img\n",
    "    rects[:, 2:] += rects[:, :2]\n",
    "    \n",
    "    #Return the location and  original image\n",
    "    return rects, img\n",
    "\n",
    "def ComputeFaceAccuracy(faceMatches, faceGroup, faceTable):\n",
    "    correct = 0\n",
    "    for i in range(len(faceGroup)):\n",
    "        faceimagePath = faceGroup[i]\n",
    "        faceimageFile = faceimagePath.split('/')[-1]\n",
    "        foundFaces = faceMatches[i]\n",
    "        refFaces = faceTable[faceimageFile]\n",
    "        \n",
    "        # Check that the faces are correct\n",
    "        if (refFaces == foundFaces):\n",
    "            correct = correct + 1\n",
    "    return float(correct)/float(len(faceGroup))\n",
    "\n",
    "def readTrainingFile(trainingFile):\n",
    "    try:\n",
    "        file_in = open(trainingFile, 'r')   #check if file exists\n",
    "    except IOError:\n",
    "        print 'Can\\'t open file ', trainingFile, ', exiting...'\n",
    "        sys.exit()\n",
    "    \n",
    "    imageDictionary = {}\n",
    "    for line in file_in:\n",
    "        columns = line.split(\":\")\n",
    "        imageFileName = str(columns[0])\n",
    "        val = int(columns[1])\n",
    "        imageDictionary[imageFileName] = val\n",
    "        #uncomment next line if you want to view the full training file\n",
    "        #print imageFileName,val\n",
    "\n",
    "    return imageDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sweep parameter lists\n",
    "scale_factor = [1.0, 1.3, 1.6, 2.0, 3.0, 4.0]\n",
    "min_neighbors = [4, 8, 16, 32]\n",
    "min_size = [(20,20), (40,40), (80,80), (160,160)]\n",
    "max_size = [(200,200), (150,150), (100,100), (50,50)]\n",
    "\n",
    "faceDataLocation = '/home/facedata/2003/01/13/big'\n",
    "\n",
    "# Location of face images : running all\n",
    "faceDirList = [\"FaceData/A\", \"FaceData/B\",\"FaceData/C\",\"FaceData/D\",\"FaceData/E\"]\n",
    "faceGroupList = [\"A\",\"B\",\"C\",\"D\",\"E\"]\n",
    "groupList = [\"A\",\"B\",\"C\",\"D\",\"E\"]\n",
    "\n",
    "# Only do one directory at a time faces, group \"A\"\n",
    "faceDirList = [\"FaceDataA\"]\n",
    "groupList = [\"A\"]\n",
    "faceGroupList = [\"A\"]\n",
    "\n",
    "\n",
    "# Location of AdaBoost Haar Cascade\n",
    "OPENCV_PATH = \"/usr/share/opencv\"\n",
    "HAAR_CASCADE_PATH = OPENCV_PATH + \"/haarcascades\"\n",
    "face_cascade = HAAR_CASCADE_PATH + '/haarcascade_frontalface_default.xml'\n",
    "cascade = cv2.CascadeClassifier(face_cascade)\n",
    "\n",
    "# Define filename to match : any .jpg \n",
    "imageFilePattern = \"*.jpg\"\n",
    "    \n",
    "# Create an empty list: will hold OpenCV images\n",
    "imageList = list()   \n",
    "\n",
    "# Get the known results of number of faces\n",
    "faceTable = readTrainingFile(\"FaceData/training.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# faceGroup\n",
    "faceGroup = {}\n",
    "for iface_dir in arange(len(faceDirList)):\n",
    "    group = faceGroupList[iface_dir]\n",
    "    faceGroup[group] = []\n",
    "    \n",
    "    for path, subdirs, files in os.walk(faceDirList[iface_dir]):\n",
    "        for name in files:\n",
    "            if fnmatch(name, imageFilePattern): # check \"*.jpg\"\n",
    "                # Create file name\n",
    "                faceFile = os.path.join(path, name)\n",
    "                faceGroup[group].append(faceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on group A\n",
      "Sweep scale factor start.\n",
      "Sweep scale factor complete.\n",
      "Sweep min neighbor start.\n",
      "Sweep min neighbor complete.\n",
      "Sweep min size start.\n",
      "Sweep min size complete.\n",
      "Sweep max size start.\n",
      "Sweep max size complete.\n",
      "Accuracy [Scale, minNeighbors, minSize, maxSize]\n",
      "[0.8444444444444444, 0.6666666666666666, 0.5777777777777777, 0.32222222222222224]\n",
      "[0.8444444444444444, 0.7444444444444445, 0.5111111111111111, 0.18888888888888888]\n",
      "[0.8444444444444444, 0.8444444444444444, 0.8444444444444444, 0.24444444444444444]\n",
      "[0.8444444444444444, 0.6555555555555556, 0.5, 0.1]\n",
      "Execution time [Scale, minNeighbors, minSize, maxSize]\n",
      "[5.14211276, 3.044851803, 2.194546373, 2.036619866]\n",
      "[4.79993379, 4.802047432, 4.798030243, 4.797245922]\n",
      "[4.79630771, 2.798026548, 0.955992968, 0.352146141]\n",
      "[4.798243021, 4.641029214, 4.457671351, 2.728558996]\n"
     ]
    }
   ],
   "source": [
    "# Use 4 lists for execution time: one for each parameter being swept\n",
    "SweepTimeMinSize = []\n",
    "SweepTimeMaxSize = []\n",
    "SweepTimeScale = []\n",
    "SweepTimeNeighbors = []\n",
    "\n",
    "# Use 4 lists for accuracy: one for each parameter being swept\n",
    "SweepAccuracyMinSize = []\n",
    "SweepAccuracyMaxSize = []\n",
    "SweepAccuracyScale = []\n",
    "SweepAccuracyNeighbors = []\n",
    "\n",
    "# one group, \"A\"\n",
    "groupList [\"A\",\"B\"]\n",
    "for group in groupList:\n",
    "    \n",
    "   print \"Working on group\", group   \n",
    "   # Sweep one parameter at a time\n",
    "    \n",
    "   # Sweep the \"scale factor\" variable\n",
    "   print \"Sweep scale factor start.\" \n",
    "   for item in scale_factor:\n",
    "      faceMatches = []\n",
    "        \n",
    "      # Start timer\n",
    "      t_start = cv2.getTickCount()\n",
    "      for index in range(len(faceGroup[group])):\n",
    "          rects, img = detectFace(faceGroup[group][index], cascade, scaleFactor=item)\n",
    "          faceMatches.append(len(rects))\n",
    "      \n",
    "      # Stop timer\n",
    "      t_stop = cv2.getTickCount()\n",
    "      t_total = (t_stop - t_start) / cv2.getTickFrequency()\n",
    "            \n",
    "      # Append time to track\n",
    "      SweepTimeScale.append(t_total)\n",
    "            \n",
    "      # Compare accuracy\n",
    "      accuracy = ComputeFaceAccuracy(faceMatches, faceGroup[group], faceTable)\n",
    "      SweepAccuracyScale.append(accuracy)\n",
    "   print \"Sweep scale factor complete.\"\n",
    "            \n",
    "   # Sweep the \"neighbor variable\"\n",
    "   print \"Sweep min neighbor start.\"          \n",
    "   for item in min_neighbors:\n",
    "      faceMatches = []\n",
    "      t_start = cv2.getTickCount()\n",
    "      for index in range(len(faceGroup[group])):\n",
    "          rects, img = detectFace(faceGroup[group][index], cascade, minNeighbors=item)\n",
    "          faceMatches.append(len(rects))\n",
    "      t_stop = cv2.getTickCount()\n",
    "      t_total = (t_stop - t_start) / cv2.getTickFrequency()\n",
    "      SweepTimeNeighbors.append(t_total)\n",
    "                    \n",
    "      # Compare accuracy\n",
    "      accuracy = ComputeFaceAccuracy(faceMatches, faceGroup[group], faceTable)\n",
    "      SweepAccuracyNeighbors.append(accuracy)\n",
    "   print \"Sweep min neighbor complete.\"                          \n",
    "            \n",
    "   # Sweep the \"min size\" variable\n",
    "   print \"Sweep min size start.\"               \n",
    "   for item in min_size:\n",
    "      faceMatches = []\n",
    "      t_start = cv2.getTickCount()\n",
    "      for index in range(len(faceGroup[group])):\n",
    "          rects, img = detectFace(faceGroup[group][index], cascade, minSize=item)\n",
    "          faceMatches.append(len(rects))\n",
    "      t_stop = cv2.getTickCount()\n",
    "      t_total = (t_stop - t_start) / cv2.getTickFrequency()\n",
    "      SweepTimeMinSize.append(t_total)\n",
    "                    \n",
    "      # Compare accuracy\n",
    "      accuracy = ComputeFaceAccuracy(faceMatches, faceGroup[group], faceTable)\n",
    "      SweepAccuracyMinSize.append(accuracy)\n",
    "   print \"Sweep min size complete.\"   \n",
    "            \n",
    "    \n",
    "   # Sweep the \"max size\" variable\n",
    "   print \"Sweep max size start.\"       \n",
    "   for item in max_size:\n",
    "      faceMatches = []\n",
    "      t_start = cv2.getTickCount()\n",
    "      for index in range(len(faceGroup[group])):\n",
    "          rects, img = detectFace(faceGroup[group][index], cascade, maxSize=item)\n",
    "          faceMatches.append(len(rects))\n",
    "      t_stop = cv2.getTickCount()\n",
    "      t_total = (t_stop - t_start) / cv2.getTickFrequency()\n",
    "      SweepTimeMaxSize.append(t_total)\n",
    "      accuracy = ComputeFaceAccuracy(faceMatches, faceGroup[group], faceTable)\n",
    "      SweepAccuracyMaxSize.append(accuracy)\n",
    "   print \"Sweep max size complete.\"   \n",
    "            \n",
    "# Print the accuracy\n",
    "print \"Accuracy [Scale, minNeighbors, minSize, maxSize]\"\n",
    "print SweepAccuracyScale\n",
    "print SweepAccuracyNeighbors\n",
    "print SweepAccuracyMinSize\n",
    "print SweepAccuracyMaxSize\n",
    "\n",
    "# Print the execution time\n",
    "print \"Execution time [Scale, minNeighbors, minSize, maxSize]\"\n",
    "print SweepTimeScale\n",
    "print SweepTimeNeighbors\n",
    "print SweepTimeMinSize\n",
    "print SweepTimeMaxSize\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Question]\n",
    "Which database is impacted the most (as the highest percentage change from the base run) based on the parameter changes: (ScaleFactor, MinNeighbors, minSize, maxSize).\n",
    "\n",
    "\n",
    "\n",
    "[Question]\n",
    "What range of setting of the (ScaleFactor, MinNeighbors, minSize, maxSize) parameters can be set without losing ANY accuracy from the base run.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
